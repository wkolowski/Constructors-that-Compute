data Z : Type :=
  | z : Z
  | s : Z -> Z :=
    | p k => k
  | p : Z -> Z :=
    | s k => k

// This is the type of integers, defined in a manner similar to the type of
// natural numbers. We have three constructors: `z`, `s` and `p`, but the type
// `Z` is not freely generated by them. There are some additional definitional 
// equalities, which stem from computations performed by the constructors.

// The computation rule for `s` says that `s (p k)` reduces to `k`. We indicate
// this by following the constructor `s` with the symbol `:=` and stating the
// computation rule in the next line using the same syntax as for ordinary
// definitions by pattern matching.

// Note that `| p k => k` means that `s (p k)` computes to `k`, not that `p k`
// computes to `k` - we don't write the function name when pattern matching,
// because it's clear from the line above.

// There is also a similar computation rule for the `p` constructor. Together
// these additional rules ensure that the only canonical forms of type `Z` are
// `z`, a finite number of applications of `s` to a `z` at the end, and finite
// number of `p`s applied to `z`. Expressions like `s (p _)` and `p (s _)` are
// not canonical forms.

// As to what the computation rules for constructors must look like, the basic
// setting I've come up with is pretty easy to grasp. First, we use ordinary
// pattern matching syntax to give the rules. Second, the pattern matching does
// not need to be exhaustive. If a pattern doesn't appear in the computation
// rules for a constructor then this pattern defines a canonical element of the
// defined type. For example, the constructor `s` doesn't have any computation
// rule for pattern `z`, so `s z` is a canonical form of `Z`. If a constructor
// has no computation rules at all, it also defines a canonical element of the
// type. For example, the constructor `z` has no associated computation rules,
// so `z` is a canonical form of the type `Z`.

// Third, computation rules can make simplifications, but they cannot make any
// complications. For example, `s (p k) => k` is a valid computation rule as it
// purges some constructors, but `s k => s (s k)` is not, because it adds more
// constructors, which then recursively add even more constructors, which
// ultimately results in nontermination. As a fast and frugal heuristic, if the
// collection of computation rules for a given constructor looks like it would
// define a normal recursive function (modulo the fact that pattern matching
// needs not be exhaustive), then these computation rules are OK.

abs : Z -> Z :=
| z   => z
| s k => s k
| p k => s (abs k)

// This is how we can compute the absolute value of an integer (with the result
// also being an integer, not a natural number). If the input is zero, then the
// result is also zero. If the input is `s k`, then our number is positive, so
// its absolute value is equal to itself. If the input is `p k`, then we know
// the number is negative, so we have to recursively flip all the `p` into `s`.

abs-abs : (k : Z) -> abs (abs k) = abs k :=
| z   => refl
| s k => refl
| p k => refl

// A well-behaved absolute value should obviously be idempotent. This is indeed
// the case and the proof of this fact is very easy - it holds by case analysis
// and computation. When discussing computation in the text, we will indicate
// it with the symbol `=>`. For example, inline we will write the computation
// performed by the constructor `s` as `s (p k) => k`.

// The `z` case is trivial, because `abs (abs z) => abs z => z` on the LHS
// (left-hand side) and `abs z => z` on the RHS (right-hand side), so that
// the goal is `z = z`, for which `refl` suffices (here `refl` stands for
// the reflexivity of equality, i.e. we have `refl x : x = x` for all `x : A`).

// In the `s` case, we have `abs (abs (s k)) => abs (s k) = s k` on the LHS and
// `abs (s k) => s k` on the RHS, so `refl` suffices.

// In the `p` case, we have `abs (abs (p k)) => abs (s (abs k)) => s (abs k)`
// on the LHS and `abs (p k) => s (abs k)` on the RHS, so `refl` suffices.

// Note that the triviality of this proof is NOT caused by the computation
// rules we attached to constructors. The proof would go through in the same
// way if `Z` didn't have them.

neg : Z -> Z :=
| z   => z
| s k => p (neg k)
| p k => s (neg k)

add : Z -> Z -> Z :=
| z     l => l
| (s k) l => s (add k l)
| (p k) l => p (add k l)

sub : Z -> Z -> Z :=
| k z     => k
| k (s l) => p (sub k l)
| k (p l) => s (sub k l)

// The definitions of negation, addition and subtraction are straightforward
// and extremely natural in comparison with the various definitions of integer
// functions from Coq's standard library.

// Negation is defined by flipping all `s` to `p` and all `p` to `s`.

// Addition is analogous to addition of naturals, but with the additional case
// for the `p` constructor.

// The definition of subtraction is the mirror image of that of addition - what
// a beautiful symmetry!

sub-spec : (k l : Z) -> sub k l = add (neg l) k :=
| k z     => refl
| k (s l') => ap p (sub-spec k l')
| k (p l') => ap s (sub-spec k l')

// We can easily prove that subtraction is the same as addition of the negated
// second argument:

// For `z` we have `sub k z => k` and `add (neg z) k => add z k => k`, so
// `refl` suffices.

// For `s l'` we have

// `sub k (s l') => p (sub k l')` on the LHS
// `add (neg (s l')) k => add (p (neg l')) k => p (add (neg l') k)` on the RHS

// and from the induction hypothesis we have

// `sub-spec k l' : sub k l' = add (neg l') k`

// so it suffices to add a `p` on both sides of this equation using `ap` (we
// use `ap` to denote the fact that functions preserve equality, i.e. we have
// `ap : {A B : Type} -> (f : A -> B) -> {x y : A} -> x = y -> f x = f y`).

// For `p l'`, the proof is analogous.

abs-neg : (k : Z) -> abs (neg k) = abs k :=
| z        => refl
| s z      => refl
| s (s k') => ap s (abs-neg (s k'))
| p z      => refl
| p (p k') => ap s (abs-neg (p k'))

// We can also prove that negating an integer doesn't change its absolute
// value. This time, however, the proof is a bit more complicated. There are
// five cases: `z`, `s z`, `s (s k')`, `p z` and `p (p k')`. Note that this set
// of patterns is considered exhaustive, because we don't need to consider the
// cases of `s (p k')` and `p (s k')`. These patterns don't match any canonical
// forms - they compute to something simpler - so we don't need to handle them.

// As for the proof, for zero, one and minus one, reflexivity suffices. The
// interesting cases are the double successor and double predecessor.

// For `s (s k')` we have (we don't reduce to normal form)
 
// LHS: `abs (neg (s (s k'))) => abs (p (neg (s k'))) => s (abs (neg (s k')))`
// RHS: `abs (s (s k')) => s (s k')`

// so the goal is convertible with `s (abs (neg (s k'))) = s (s k')`.

// From the induction hypothesis/recursive call after some computation we get:

// `abs-neg (s k') : abs (neg (s k')) = s k'`.

// so it suffices to apply `s` on both sides of the equation using ap. The case
// of `p (p k')` is analogous.

// Why did we go with this particular 5-case pattern matching instead of the
// standard one? Note that a simple recursive call on `k'` results in

// `abs-neg k' : abs (neg k') = abs k'`

// which is not very useful in the `s k'` case, as there we have

// LHS: `abs (neg (s k')) => abs (p (neg k')) => s (abs (neg k'))`
// RHS: `abs (s k') => s k'`

// and so the induction hypothesis is not very useful in proving this goal. The
// case `p k'` case is similar, so the standard 3-case pattern matching won't
// work for this proof. This is why we need to consider the cases of `s z` and
// `s (s k')` (and `p z` and `p (p k')`, respectively) separately.

// Below there are some more theorems in the same vein.

add-assoc : (k l m : Z) -> add (add k l) m = add k (add l m) :=
| z      l m => refl
| (s k') l m => ap s (add-assoc k' l m)
| (p k') l m => ap p (add-assoc k' l m)

// Nothing to see here, move along!

add-z : (k : Z) -> add k z = k :=
| z    => refl
| s k' => ap s (add-z k')
| p k' => ap p (add-z k')

// The proof is analogous to the analogous theorem for the natural numbers.

add-s : (k l : Z) -> add k (s l) = s (add k l) :=
| z      l => refl
| (s k') l => ap s (add-s k' l)
| (p k') l => ap p (add-s k' l)

// This one is a bit tougher. The `z` case is trivial and the `s k'` case is
// pretty easy, but `p k'` is much more mentally demanding because of the
// computation rules for `p`. We have:

// LHS: `add (p k') (s l) => p (add k' (s l))`
// RHS: `s (add (p k') l) => s (p (add k' l)) => add k' l`

// so the goal is `p (add k' (s l)) = add k' l`. The induction hypothesis is

// `add-s k' l : add k' (s l) = s (add k' l)`

// so after adding `p` on both sides using `ap` we get
// `ap p (add-s k' l) : p (add k' (s l)) = p (s add k' l)`
// whose type computes to `p (add k' (s l)) = add k' l`,
// so the proof is finished.

add-p : (k l : Z) -> add k (p l) = p (add k l) :=
| z      l => refl
| (s k') l => ap s (add-p k' l)
| (p k') l => ap p (add-p k' l)

// This one is analogous to `add-s`.

// More functions.

zeq : Z -> Z -> Bool :=
| z      z      => true
| (s k') (s l') => zeq k' l'
| (p k') (p l') => zeq k' l'
| _      _      => false

zeq-neg : (k l : Z) -> zeq (neg k) (neg l) = zeq k l :=
| z      z      => refl
| (s k') (s l') => zeq-neg k' l'
| (p k') (p l') => zeq-neg k' l'
| _      _      => refl

// The last clause in the proof is a bit controversial. If we treat it as unfolding
// to the patterns `z (s _)`, `z (p _)`, etc., then it's valid. But if not and for
// example it's just `z l` with the hypothesis `l <> z`, then it doesn't compute
// and the proof is not valid. TODO!

// `zeq (neg (s k')) (neg (s l')) => zeq (p (neg k')) (p (neg l')) => zeq (neg k') (neg l')`
