data Z : Type
| z
| s with (pred : Z)
  | p k => k
| p with (succ : Z)
  | s k => k

// This is the type of integers, defined in a manner similar to the type of
// natural numbers. We have three constructors: `z`, `s` and `p`, but the type
// `Z` is not freely generated by them. There are some additional definitional 
// equalities, which stem from computations performed by the constructors.

// The computation rule for `s` says that `s (p k)` reduces to `k`. We indicate
// this by stating the computation rule in the next line using the same syntax
// as for ordinary definitions by pattern matching.

// Note that `| p k => k` means that `s (p k)` computes to `k`, not that `p k`
// computes to `k` - we don't write the constructor name when pattern matching,
// because it's clear from the line above.

// There is also a similar computation rule for the `p` constructor. Together
// these additional rules ensure that the only canonical forms of type `Z` are
// `z`, a finite number of applications of `s` to a `z` at the end, and finite
// number of applications of `p` to a `z` at the end. Expressions like
// `s (p _)` and `p (s _)` are not canonical forms.

// As to what the computation rules for constructors must look like, the basic
// setting I've come up with is pretty easy to grasp. First, we use ordinary
// pattern matching syntax to give the rules. Second, the pattern matching does
// not need to be exhaustive. If a pattern doesn't appear in the computation
// rules for a constructor then this pattern defines a canonical element of the
// defined type. For example, the constructor `s` doesn't have any computation
// rule for pattern `z`, so `s z` is a canonical form of type `Z`. If a constructor
// has no computation rules at all, it also defines a canonical element of the
// type. For example, the constructor `z` has no associated computation rules,
// so `z` is a canonical form of the type `Z`.

// Third, computation rules can make simplifications, but they cannot make any
// complications. For example, `s (p k) => k` is a valid computation rule as it
// purges some constructors, but `s k => s (s k)` is not, because it adds more
// constructors, which then recursively add even more constructors, which
// ultimately results in nontermination. As a fast and frugal heuristic, if the
// collection of computation rules for a given constructor looks like it would
// define a normal recursive function (modulo the fact that pattern matching
// needs not be exhaustive), then these computation rules are OK.

abs : Z -> Z
| z   => z
| s k => s k
| p k => s (abs k)

// This is how we can compute the absolute value of an integer (with the result
// also being an integer, not a natural number). If the input is zero, then the
// result is also zero. If the input is `s k`, then our number is positive, so
// its absolute value is equal to itself. If the input is `p k`, then we know
// the number is negative, so we have to recursively flip all the `p` into `s`.

abs-abs : (k : Z) -> abs (abs k) = abs k
| z   => refl
| s k => refl
| p k => refl

// A well-behaved absolute value should obviously be idempotent. This is indeed
// the case and the proof of this fact is very easy - it holds by case analysis
// and computation. When discussing computation in the text, we will indicate
// it with the symbol `=>`. For example, inline we will write the computation
// performed by the constructor `s` as `s (p k) => k`.

// The `z` case is trivial, because `abs (abs z) => abs z => z` on the LHS
// (left-hand side) and `abs z => z` on the RHS (right-hand side), so that
// the goal is `z = z`, for which `refl` suffices (here `refl` stands for
// the reflexivity of equality, i.e. we have `refl x : x = x` for all `x : A`).

// In the `s` case, we have `abs (abs (s k)) => abs (s k) = s k` on the LHS and
// `abs (s k) => s k` on the RHS, so `refl` suffices.

// In the `p` case, we have `abs (abs (p k)) => abs (s (abs k)) => s (abs k)`
// on the LHS and `abs (p k) => s (abs k)` on the RHS, so `refl` suffices.

// Note that the triviality of this proof is NOT caused by the computation
// rules we attached to constructors. The proof would go through in the same
// way if `Z` didn't have them.

neg : Z -> Z
| z   => z
| s k => p (neg k)
| p k => s (neg k)

add : Z -> Z -> Z
| z  , l => l
| s k, l => s (add k l)
| p k, l => p (add k l)

sub : Z -> Z -> Z
| k, z   => k
| k, s l => p (sub k l)
| k, p l => s (sub k l)

// The definitions of negation, addition and subtraction are straightforward
// and extremely natural in comparison with the various definitions of integer
// functions from Coq's standard library.

// Negation is defined by flipping all `s` to `p` and all `p` to `s`.

// Addition is analogous to addition of naturals, but with the additional case
// for the `p` constructor.

// The definition of subtraction is the mirror image of that of addition - what
// a beautiful symmetry!

sub-spec : (k l : Z) -> sub k l = add (neg l) k
| k, z    => refl
| k, s l' => ap p (sub-spec k l')
| k, p l' => ap s (sub-spec k l')

// We can easily prove that subtraction is the same as addition of the negated
// second argument:

// For `z` we have `sub k z => k` and `add (neg z) k => add z k => k`, so
// `refl` suffices.

// For `s l'` we have

// `sub k (s l') => p (sub k l')` on the LHS
// `add (neg (s l')) k => add (p (neg l')) k => p (add (neg l') k)` on the RHS

// and from the induction hypothesis we have

// `sub-spec k l' : sub k l' = add (neg l') k`

// so it suffices to add a `p` on both sides of this equation using `ap` (we
// use `ap` to denote the fact that functions preserve equality, i.e. we have
// `ap : #(A B : Type) (f : A -> B) #(x y : A) -> x = y -> f x = f y`).

// For `p l'`, the proof is analogous.

abs-neg : (k : Z) -> abs (neg k) = abs k
| z        => refl
| s z      => refl
| s (s k') => ap s (abs-neg (s k'))
| p z      => refl
| p (p k') => ap s (abs-neg (p k'))

// We can also prove that negating an integer doesn't change its absolute
// value. This time, however, the proof is a bit more complicated. There are
// five cases: `z`, `s z`, `s (s k')`, `p z` and `p (p k')`. Note that this set
// of patterns is considered exhaustive, because we don't need to consider the
// cases of `s (p k')` and `p (s k')`. These patterns don't match any canonical
// forms - they compute to something simpler - so we don't need to handle them.

// As for the proof, for zero, one and minus one, reflexivity suffices. The
// interesting cases are the double successor and double predecessor.

// For `s (s k')` we have (we don't reduce to normal form)
 
// LHS: `abs (neg (s (s k'))) => abs (p (neg (s k'))) => s (abs (neg (s k')))`
// RHS: `abs (s (s k')) => s (s k')`

// so the goal is convertible with `s (abs (neg (s k'))) = s (s k')`.

// From the induction hypothesis/recursive call after some computation we get:

// `abs-neg (s 
Note that as of now, the patterns allowed for constructors' computation rules are using first-match semantics, but that may change in the future.k') : abs (neg (s k')) = s k'`.

// so it suffices to apply `s` on both sides of the equation using ap. The case
// of `p (p k')` is analogous.

// Why did we go with this particular 5-case pattern matching instead of the
// standard one? Note that a simple recursive call on `k'` results in

// `abs-neg k' : abs (neg k') = abs k'`

// which is not very useful in the `s k'` case, as there we have

// LHS: `abs (neg (s k')) => abs (p (neg k')) => s (abs (neg k'))`
// RHS: `abs (s k') => s k'`

// and so the induction hypothesis is not very useful in proving this goal. The
// case `p k'` case is similar, so the standard 3-case pattern matching won't
// work for this proof. This is why we need to consider the cases of `s z` and
// `s (s k')` (and `p z` and `p (p k')`, respectively) separately.

// Below there are some more theorems in the same vein.

add-assoc : (k l m : Z) -> add (add k l) m = add k (add l m)
| z     l, m => refl
| s k', l, m => ap s (add-assoc k' l m)
| p k', l, m => ap p (add-assoc k' l m)

// Nothing to see here, move along!

add-z : (k : Z) -> add k z = k
| z    => refl
| s k' => ap s (add-z k')
| p k' => ap p (add-z k')

// The proof is analogous to the analogous theorem for the natural numbers.

add-s : (k l : Z) -> add k (s l) = s (add k l)
| z   , l => refl
| s k', l => ap s (add-s k' l)
| p k', l => ap p (add-s k' l)

// This one is a bit tougher. The `z` case is trivial and the `s k'` case is
// pretty easy, but `p k'` is much more mentally demanding because of the
// computation rules for `p`. We have:

// LHS: `add (p k') (s l) => p (add k' (s l))`
// RHS: `s (add (p k') l) => s (p (add k' l)) => add k' l`

// so the goal is `p (add k' (s l)) = add k' l`. The induction hypothesis is

// `add-s k' l : add k' (s l) = s (add k' l)`

// so after adding `p` on both sides using `ap` we get
// `ap p (add-s k' l) : p (add k' (s l)) = p (s add k' l)`
// whose type computes to `p (add k' (s l)) = add k' l`,
// so the proof is finished.

add-p : (k l : Z) -> add k (p l) = p (add k l)
| z   , l => refl
| s k', l => ap s (add-p k' l)
| p k', l => ap p (add-p k' l)

// This one is analogous to `add-s`.

// More functions.

zeq : Z -> Z -> Bool
| z  , z   => tt
| s k, s l => zeq k l
| p k, p l => zeq k l
| _  , _   => false

zeq-neg : (k l : Z) -> zeq (neg k) (neg l) = zeq k l
| z   , z    => refl
| s k', s l' => zeq-neg k' l'
| p k', p l' => zeq-neg k' l'
| _   , _    => refl

// The last clause in the proof is a bit controversial. If we treat it as unfolding
// to the patterns `z (s _)`, `z (p _)`, etc., then it's valid. But if not and for
// example it's just `z l` with the hypothesis `l <> z`, then it doesn't compute
// and the proof is not valid. TODO!

// `zeq (neg (s k')) (neg (s l')) => zeq (p (neg k')) (p (neg l')) => zeq (neg k') (neg l')`

// The standard definition of addition is structurally recursive on the first
// argument, which means that we get computation rules like `add z l => l` and
// so on. But we need to manually prove that `add k z => k`, `add k (s l) => s (add k l)`
// and `add k (p l) => p (add k l)`, because even when the second argument is known, the
// whole thing is in normal form (neutral to be precise) and thus there's no computation.
// Let's make our lives a bit easier with overlapping patterns.

%OverlappingPatterns
add : Z -> Z -> Z
| z  , l   => l
| s k, l   => s (add k l)
| p k, l   => p (add k l)
| k  , z   => k
| k  , s l => s (add k l)
| k  , p l => p (add k l)

// In short: in the new definition of `add`, we get three more pattern matching
// clauses, which make `add k z` compute to `k` and similarly for `s` and `p`.
// This is INSANELY comfortable and allows us to easily prove theorems which
// otherwise are much more annoying, but ultimately easy, like commutativity of
// addition.

add-comm : (k l : Z) -> add k l = add l k
| z   , l => refl
| s k', l => ap s (add-comm k' l)
| p k', l => ap p (add-comm k' l)

// Proving commutativity of addition is now as easy as proving associativity.

%OverlappingPatterns
sub : Z -> Z -> Z
| k  , z   => k
| k  , s l => p (sub k l)
| k  , p l => s (sub k l)
| s k, l   => s (sub k l)
| p k, l   => p (sub k l)

// We can also have more computation rules for subtraction. Note, however, that
// we don't want to compute `sub z l`, because it would need to compute to
// `neg l` and this would probably be awkward in some situations... although
// this is just my speculation.

sub-diag : (k : Z) -> sub k k = z
| z    => refl
| s k' => sub-diag k'
| p k' => sub-diag k'

// With these bonus computation rules, proving that k - k = 0 is extremely
// easy. You don't want to know how much harder it would be without them...

// For `z`, `refl` suffices. For `s k'`, we have

// LHS: `sub (s k') (s k') => p (sub (S k') k') => p (s (sub k' k')) =>
//       sub k' k'`
// RHS: `z`

// so it suffices to use the induction hypothesis. The case of `p k'` is
// analogous.

sub-add : (k l m : Z) -> sub k (add l m) = sub (sub k l) m
| k, z    m => refl
| k, s l' m => ap p (sub-add k l' m)
| k, p l' m => ap s (sub-add k l' m)

// LHS: `sub k (add (s l') m) => sub k (s (add l' m)) => p (sub k (add l' m))`
// RHS: `sub (sub k (s l')) m => sub (p (sub k l')) m => p (sub (sub k l') m)`

// LHS: `sub k (add (p l') m) => sub k (p (add l' m)) => s (sub k (add l' m))`
// RHS: `sub (sub k (p l')) m => sub (s (sub k l')) m => s (sub (sub k l') m)`